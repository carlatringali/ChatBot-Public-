{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyttsx3 in c:\\users\\marid\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.97)\n",
      "Requirement already satisfied: comtypes in c:\\users\\marid\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pyttsx3) (1.4.7)\n",
      "Requirement already satisfied: pypiwin32 in c:\\users\\marid\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pyttsx3) (223)\n",
      "Requirement already satisfied: pywin32 in c:\\users\\marid\\appdata\\roaming\\python\\python311\\site-packages (from pyttsx3) (306)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai==0.28 in c:\\users\\marid\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.28.0)\n",
      "Requirement already satisfied: requests>=2.20 in c:\\users\\marid\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai==0.28) (2.32.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\marid\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai==0.28) (4.66.5)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\marid\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai==0.28) (3.10.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\marid\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\marid\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.20->openai==0.28) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\marid\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.20->openai==0.28) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\marid\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.20->openai==0.28) (2024.8.30)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\marid\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->openai==0.28) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\marid\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->openai==0.28) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\marid\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->openai==0.28) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\marid\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->openai==0.28) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\marid\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->openai==0.28) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\marid\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->openai==0.28) (1.11.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\marid\\appdata\\roaming\\python\\python311\\site-packages (from tqdm->openai==0.28) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: SpeechRecognition in c:\\users\\marid\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.10.4)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\marid\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from SpeechRecognition) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\marid\\appdata\\roaming\\python\\python311\\site-packages (from SpeechRecognition) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\marid\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.26.0->SpeechRecognition) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\marid\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.26.0->SpeechRecognition) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\marid\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.26.0->SpeechRecognition) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\marid\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.26.0->SpeechRecognition) (2024.8.30)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.Requirement already satisfied: scikit-learn in c:\\users\\marid\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\marid\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\marid\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\marid\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\marid\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install pyttsx3\n",
    "%pip install openai==0.28\n",
    "%pip install SpeechRecognition \n",
    "%pip install scikit-learn\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assunto: Siamo un'azienda produttrice di giocattoli, attraverso un form online i clienti possono realizzare il loro gioco personalizzandolo completamente che verrà successivamente inviato alla linea di assemblaggio che si occuperà di realizzare il prodotto ed effettuare un controllo qualità.\n",
    "\n",
    "I PROCESSI DI NOSTRO INTERESSE SONO: L'ASSEMBLAGGIO E IL CONTROLLO QUALITA'\n",
    "\n",
    "PROCESSO AS IS:\n",
    "- Ricezione dell'ordine:\n",
    "L'operatore riceve le foto del prodotto finito e la distinta base.\n",
    "- Istruzioni:\n",
    "L'operatore usa la foto per capire come assemblare il prodotto e la BOM per identificare i pezzi, senza istruzioni specifiche.\n",
    "- Assemblaggio:\n",
    "Procede con l'assemblaggio basandosi sulla foto e l'elenco dei pezzi deducendo la sequenza corretta.\n",
    "- Controllo qualità (compito affidato ad un altro operatore in un'altra stazione):\n",
    "Confronta visivamente il prodotto finito con la foto per verificarne la correttezza.\n",
    "\n",
    "\n",
    "Assunto : La distinta base (BOM) e la foto del prodotto finito vengono automaticamente tradotte in un manuale di istruzioni dettagliato tramite AI.\n",
    "PROCESSO TO BE:\n",
    "- Ricezione dell'ordine:\n",
    "riceve la commessa con il nome del prodotto finito e interrgoa il chatbot per ricevere assistenza.\n",
    "Il chatbot riceve il manuale generato  che viene automaticamente salvato e guida l'operatore passo-passo nel montaggio, fornendo istruzioni chiare sui pezzi da utilizzare e l'ordine di assemblaggio.\n",
    "\n",
    "- Assemblaggio:\n",
    "L'operatore segue le istruzioni del chatbot, che fornisce supporto e feedback in tempo reale durante l'assemblaggio.\n",
    "\n",
    "- Controllo qualità:\n",
    "Il pezzo scorre e attraverso object detection viene eseguita una scansione visiva del prodotto finito, verificando automaticamente la correttezza del montaggio e segnalando eventuali errori.\n",
    "\n",
    "\n",
    "Criticità del Processo As Is:\n",
    "La mancanza di un manuale dettagliato obbliga l'operatore a dedurre la sequenza di montaggio, con il rischio di montare i pezzi nell'ordine sbagliato.\n",
    "Controllo qualità soggettivo:\n",
    "Il controllo qualità è manuale e visivo, basato sull'osservazione dell'operatore, il che può portare a errori non rilevati o difetti nascosti.\n",
    "Non ci sono strumenti che forniscano un feedback immediato all'operatore durante l'assemblaggio, quindi eventuali errori vengono scoperti solo alla fine, aumentando i costi di correzione.\n",
    "\n",
    "Vantaggi implementazione chatbot:\n",
    "meno errori grazie alle istruzioni, un operatore in meno e tempo risparmiato\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot attivo: dimmi cosa vuoi fare. Digita 'esci' per terminare.\n",
      "Tu: devo assemblare la giraffa, che pezzi devo utilizzare?\n",
      "Chatbot: Per assemblare la giraffa, hai bisogno dei seguenti pezzi:\n",
      "\n",
      "- 2 pezzi Verde Grande\n",
      "- 2 pezzi Celeste Triplo\n",
      "- 4 pezzi Blu Unico\n",
      "- 1 pezzo Arancione Punta\n",
      "\n",
      "Se hai bisogno di ulteriori informazioni o istruzioni su una fase specifica, non esitare a chiedere.\n",
      "Tu: quale è la prima fase?\n",
      "Chatbot: La prima fase è l'Assemblaggio del Modulo Corpo. Segui le istruzioni per predisporre i 2 pezzi Verde Grande in modo parallelo e distanziati, quindi sovrapporre i 2 pezzi Celeste Triplo sui due agganci esterni dei pezzi Verde, unendo le estremità.\n",
      "Tu: fase finale\n",
      "Chatbot: La fase finale consiste nel fissare ogni Zampa agli agganci inferiori del corpo, installare il Collo e la Testa sull'aggancio superiore del corpo, orientando la testa verso l'esterno. Assicurati che tutti i componenti siano fissati correttamente e che non ci siano parti mancanti. Successivamente, procedi con la verifica di qualità tramite computer vision.\n",
      "\n",
      "Il lavoro di assemblaggio della giraffa è terminato. Se hai bisogno di ulteriori informazioni o assistenza, non esitare a chiedere.\n"
     ]
    }
   ],
   "source": [
    "#prompt3 con meno chunk_ pare funzioni!!! (SI) \n",
    "import re\n",
    "import openai\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# Imposta direttamente la chiave API qui\n",
    "openai.api_key = 'sk-du21AXQeS5dbEhauUmmaLCRmm9jzyYKY7wemdgGIFET3BlbkFJ4r1IqdlWQ_lhECmi3PGJCy-V0M-_z_7EqiTT7jCHsA'  # Sostituisci con la tua chiave API\n",
    "\n",
    "# Definisci i percorsi dei manuali\n",
    "manuali_prodotti = {\n",
    "    'giraffa': r'C:\\Users\\marid\\OneDrive\\Desktop\\PSF\\Giraffa_.txt',\n",
    "    'treno_arancio': r'C:\\Users\\marid\\OneDrive\\Desktop\\PSF\\TrenoArancio_.txt',\n",
    "    'treno_viola': r'C:\\Users\\marid\\OneDrive\\Desktop\\PSF\\TrenoViola_.txt',\n",
    "}\n",
    "\n",
    "# Funzione per caricare e dividere un manuale in chunk\n",
    "def carica_e_dividi_manuali(filename, chunk_size=500):\n",
    "    manual_chunks = []\n",
    "    with open(filename, 'r', encoding='utf-8') as file:\n",
    "        testo = file.read()\n",
    "        paragrafi = testo.split(\"\\n\\n\")\n",
    "        chunk = \"\"\n",
    "        for paragrafo in paragrafi:\n",
    "            if len(chunk) + len(paragrafo) < chunk_size:\n",
    "                chunk += paragrafo + \"\\n\\n\"\n",
    "            else:\n",
    "                manual_chunks.append(chunk.strip())\n",
    "                chunk = paragrafo + \"\\n\\n\"\n",
    "        if chunk:\n",
    "            manual_chunks.append(chunk.strip())\n",
    "    return manual_chunks\n",
    "\n",
    "# Funzione per trovare il chunk rilevante con +-2 chunk\n",
    "def trova_chunk_rilevante(domanda, manual_chunks, vicinanza=2):\n",
    "    documenti = [domanda] + manual_chunks\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform(documenti)\n",
    "    similarita = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:]).flatten()\n",
    "    \n",
    "    # Trova l'indice del chunk più rilevante\n",
    "    indice_miglior_chunk = np.argmax(similarita)\n",
    "    \n",
    "    # Crea una lista dei chunk intorno a quello rilevante, includendo i chunk vicini\n",
    "    chunk_rilevanti = []\n",
    "    inizio = max(0, indice_miglior_chunk - vicinanza)\n",
    "    fine = min(len(manual_chunks), indice_miglior_chunk + vicinanza + 1)\n",
    "    \n",
    "    # Aggiungi i chunk dalla lista ristretta\n",
    "    for i in range(inizio, fine):\n",
    "        chunk_rilevanti.append(manual_chunks[i])\n",
    "    \n",
    "    return \"\\n\\n\".join(chunk_rilevanti)  # Restituisce i chunk concatenati come un unico testo\n",
    "\n",
    "# Funzione per interagire con OpenAI\n",
    "def interroga_openai(domanda, chunk_rilevante, memoria, temperatura=0.0):\n",
    "    prompt_memoria = \"\\n\".join(memoria)\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Manuale di riferimento: \\n{chunk_rilevante}\\n\\nConversazione precedente: {prompt_memoria}\\n\\nDomanda: {domanda}\\n\n",
    "    Sei un assistente virtuale specializzato nell'assemblaggio di prodotti. Si tratta di un prodotto modulare. \n",
    "    Il tuo compito è aiutare un operatore a seguire correttamente le istruzioni di un manuale di assemblaggio.\n",
    "    - Se l'utente chiede i materiali, fornisci solo la lista dei materiali necessari senza aggiungere istruzioni di assemblaggio.\n",
    "    - Se l'utente chiede i moduli, fornisci solo la lista dei moduli necessari senza aggiungere istruzioni di assemblaggio.\n",
    "    - Se l'utente utilizza i numeri ordinali al posto dei numeri cardinali, fornisci la fase giusta corrispondemte.\n",
    "    - Se l'utente chiede istruzioni per una fase specifica, fornisci solo le istruzioni per quella fase.\n",
    "    - Se l'utente chiede di procedere con la fase successiva o precedente, fornisci le istruzioni per la fase successiva o precedente.\n",
    "    - Non fornire informazioni non richieste e non procedere con le fasi di assemblaggio a meno che l'utente non lo chieda esplicitamente.\n",
    "    - Restituiscimi le risposte a tutte le domande.\n",
    "    - Nel momento in cui arrivi alla fase finale, restituisci un messaggio in cui spieghi che il lavoro è terminato.\n",
    "    \"\"\"\n",
    " \n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[{\"role\": \"system\", \"content\": \"Sei un assistente esperto che aiuta con l'assemblaggio di prodotti seguendo il manuale, non inventi nulla.\"},\n",
    "                  {\"role\": \"user\", \"content\": prompt}],\n",
    "        max_tokens=500,\n",
    "        temperature=temperatura\n",
    "    )\n",
    "    return response['choices'][0]['message']['content']\n",
    "\n",
    "# Funzione principale per generare una risposta con +-2 chunk\n",
    "def genera_risposta(domanda, manual_chunks, memoria, temperatura=0.0):\n",
    "    chunk_rilevante = trova_chunk_rilevante(domanda, manual_chunks)\n",
    "    risposta = interroga_openai(domanda, chunk_rilevante, memoria, temperatura)\n",
    "    return risposta\n",
    "\n",
    "# Funzione per selezionare il manuale in base all'input dell'utente\n",
    "def seleziona_manuale(user_input):\n",
    "    if re.search(r'giraffa', user_input, re.IGNORECASE):\n",
    "        return 'giraffa'\n",
    "    elif re.search(r'treno arancio', user_input, re.IGNORECASE):\n",
    "        return 'treno_arancio'\n",
    "    elif re.search(r'treno viola', user_input, re.IGNORECASE):\n",
    "        return 'treno_viola'\n",
    "    return None\n",
    "\n",
    "# Funzione di interfaccia del chatbot\n",
    "def chatbot_interface():\n",
    "    manual_chunks = {}\n",
    "    memoria = []  # Inizializza la memoria della conversazione\n",
    "    \n",
    "    # Carica e divide i manuali\n",
    "    for product, path in manuali_prodotti.items():\n",
    "        manual_chunks[product] = carica_e_dividi_manuali(path)\n",
    "\n",
    "    prodotto_corrente = None  # Variabile per tenere traccia del prodotto corrente\n",
    "\n",
    "    print(\"Chatbot attivo: dimmi cosa vuoi fare. Digita 'esci' per terminare.\")\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"Tu: \")  # Input dell'utente\n",
    "        \n",
    "        if user_input.lower() == \"esci\":\n",
    "            break\n",
    "        \n",
    "        manual_name = seleziona_manuale(user_input)\n",
    "        \n",
    "        if manual_name:\n",
    "            prodotto_corrente = manual_name  # Aggiorna il prodotto corrente\n",
    "            risposta = genera_risposta(user_input, manual_chunks[manual_name], memoria)\n",
    "            memoria.append(f\"Utente: {user_input}\\nChatbot: {risposta}\")\n",
    "            print(f\"Tu: {user_input}\")\n",
    "            print(f\"Chatbot: {risposta}\")\n",
    "        elif prodotto_corrente:\n",
    "            risposta = genera_risposta(user_input, manual_chunks[prodotto_corrente], memoria)  # Usa il prodotto corrente\n",
    "            memoria.append(f\"Utente: {user_input}\\nChatbot: {risposta}\")\n",
    "            print(f\"Tu: {user_input}\")\n",
    "            print(f\"Chatbot: {risposta}\")\n",
    "        else:\n",
    "            print(\"Chatbot: Non ho trovato il prodotto specificato. Riprova.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    chatbot_interface()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
