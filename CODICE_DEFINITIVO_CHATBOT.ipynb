{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87b4610987ce40f584d8af46a6e54e05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Prodotto:', options=(('Seleziona un prodotto', None), ('Treno Arancio', 'Treno Arancio')…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e85f3f9bf9cd4d8f9839d6c52b7ded15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Domanda:', placeholder='Inserisci la tua domanda')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90ab3adae6eb4cdeaf919137224e7cf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='primary', description='Invia', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d4b4670b2724d96a2cac22ce4365801",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='', description='Conversazione:', layout=Layout(height='400px', width='100%'), placeholder='Le …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Ho modificato la struttuta dei manuali per evitare i conflitti. In particolare nei moduli del treno arancio e viola nella parte della base anteriore\n",
    "#ho elimitato la frase assemblaggio finale poichè per eliminare il problema della presenza costante dell'assemblaggio finale nella risposta, in questo codice\n",
    "#c'è una funzione che elimina la parte di testo che contiene \"assemblaggio finale\" dalle risposte del chatbot o a meno che non vengia chiesto specificatamente dall'autente.\n",
    "#Questa funzione però non permetteva al cahtbot di dare istruzioni riguardo la base anteriore perchè nel manuale, in quella sezione, copariva la frase assemblaggio finale.\n",
    "#In più ho modificato l'interfaccia perchè con l'altro codice le frasi troppo lunge le troncava con dei puntini di sospensione, in questo modo la risposta si legge completamente.\n",
    "#NB:quando l'utente pone la domanda il chatbot impiega qualche secondo a restituire la risposta.\n",
    "\n",
    "import requests\n",
    "import re\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Configura l'API di GPT-2\n",
    "API_URL = \"https://api-inference.huggingface.co/models/gpt2\"\n",
    "headers = {\"Authorization\": \"Bearer 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\"}\n",
    "\n",
    "def query_gpt2(prompt):\n",
    "    response = requests.post(API_URL, headers=headers, json={\"inputs\": prompt})\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        return {\"error\": \"Request failed with status code \" + str(response.status_code)}\n",
    "\n",
    "def preprocess_text(text):\n",
    "    return text.lower()\n",
    "\n",
    "class ManualLoader:\n",
    "    def __init__(self, manual_paths):\n",
    "        self.manuals = {}\n",
    "        self.load_manuals(manual_paths)\n",
    "\n",
    "    def load_manuals(self, paths):\n",
    "        for name, path in paths.items():\n",
    "            with open(path, 'r', encoding='utf-8') as file:\n",
    "                content = file.read()\n",
    "                self.manuals[name] = self._split_into_chunks(content)\n",
    "\n",
    "    def _split_into_chunks(self, text):\n",
    "        chunks = [preprocess_text(chunk.strip()) for chunk in text.split('---') if chunk.strip()]\n",
    "        return chunks\n",
    "\n",
    "class AssemblyAssistantBot:\n",
    "    def __init__(self, manuals):\n",
    "        self.manual_loader = ManualLoader(manuals)\n",
    "        self.vectorizer = TfidfVectorizer()\n",
    "        self._fit_vectorizer()\n",
    "\n",
    "    def _fit_vectorizer(self):\n",
    "        all_chunks = []\n",
    "        for chunks in self.manual_loader.manuals.values():\n",
    "            all_chunks.extend(chunks)\n",
    "        self.vectorizer.fit(all_chunks)\n",
    "\n",
    "    def handle_query(self, product, query):\n",
    "        # Ricerca nei manuali\n",
    "        response_from_manuals = self._search_in_manuals(product, query)\n",
    "        \n",
    "        # Usa GPT-2 per arricchire la risposta\n",
    "        if response_from_manuals:\n",
    "            gpt_prompt = f\"Given the following information from the manual: {', '.join(response_from_manuals)}, provide a precise answer to the question: {query}\"\n",
    "            gpt_response = query_gpt2(gpt_prompt)\n",
    "        \n",
    "            if 'generated_text' in gpt_response:\n",
    "                return response_from_manuals + [self._filter_gpt_response(gpt_response['generated_text'].strip(), query)]\n",
    "        \n",
    "        return response_from_manuals\n",
    "\n",
    "    def _search_in_manuals(self, product, query):\n",
    "        query = preprocess_text(query)\n",
    "        if product not in self.manual_loader.manuals:\n",
    "            return [\"Manuale non trovato.\"]\n",
    "        \n",
    "        chunks = self.manual_loader.manuals.get(product, [])\n",
    "        if not chunks:\n",
    "            return [\"Nessuna informazione trovata nel manuale per questo prodotto.\"]\n",
    "        \n",
    "        # Filtra la sezione \"assemblaggio finale\" se non richiesta esplicitamente\n",
    "        include_final_assembly = any(kw in query.lower() for kw in ['assemblaggio finale', 'fase finale', 'finale'])\n",
    "        if not include_final_assembly:\n",
    "            chunks = [chunk for chunk in chunks if 'assemblaggio finale' not in chunk.lower()]\n",
    "        \n",
    "        # Trova i chunk più simili alla query\n",
    "        query_vec = self.vectorizer.transform([query])\n",
    "        chunk_vecs = self.vectorizer.transform(chunks)\n",
    "        similarities = cosine_similarity(query_vec, chunk_vecs).flatten()\n",
    "\n",
    "        # Riduci la soglia per trovare più risposte\n",
    "        results = [chunks[index] for index, similarity in enumerate(similarities) if similarity > 0.1]\n",
    "        \n",
    "        # Riduci la lunghezza delle risposte\n",
    "        results = self._truncate_responses(results)\n",
    "        \n",
    "        return results if results else [\"Nessuna informazione trovata.\"]\n",
    "\n",
    "    def _filter_gpt_response(self, response, query):\n",
    "        # Includi la sezione \"assemblaggio finale\" solo se esplicitamente richiesta\n",
    "        if 'assemblaggio finale' in query.lower():\n",
    "            return response  # Mantieni l'intera risposta se richiesta\n",
    "        \n",
    "        # Altrimenti, filtra la sezione\n",
    "        pattern = re.compile(r'assemblaggio finale dei moduli.*', re.DOTALL)\n",
    "        filtered_response = pattern.split(response)[0].strip()\n",
    "        \n",
    "        return filtered_response\n",
    "\n",
    "    def _truncate_responses(self, responses, max_length=2000):\n",
    "        truncated_responses = []\n",
    "        for response in responses:\n",
    "            if len(response) > max_length:\n",
    "                truncated_responses.append(response[:max_length] + '...')\n",
    "            else:\n",
    "                truncated_responses.append(response)\n",
    "        return truncated_responses\n",
    "\n",
    "def on_submit(_):\n",
    "    product = product_dropdown.value\n",
    "    query = query_input.value\n",
    "    if product and query:\n",
    "        response = bot.handle_query(product, query)\n",
    "        conversation_output.value = f\"Tu: {query}\\n\\n\" + \"\\n\\n\".join([f\"Bot: {info}\" for info in response])\n",
    "        query_input.value = \"\"\n",
    "    else:\n",
    "        conversation_output.value = \"Bot: Seleziona un prodotto e inserisci una domanda.\"\n",
    "\n",
    "# Percorsi ai manuali\n",
    "manuals = {\n",
    "    \"Treno Arancio\": \"C:\\\\Users\\\\marid\\\\OneDrive\\\\Desktop\\\\Progetto SF\\\\TrenoArancio.txt\",\n",
    "    \"Treno Viola\": \"C:\\\\Users\\\\marid\\\\OneDrive\\\\Desktop\\\\Progetto SF\\\\TrenoViola.txt\",\n",
    "    \"Giraffa\": \"C:\\\\Users\\\\marid\\\\OneDrive\\\\Desktop\\\\Progetto SF\\\\Giraffa.txt\"\n",
    "}\n",
    "\n",
    "# Creazione del bot\n",
    "bot = AssemblyAssistantBot(manuals)\n",
    "\n",
    "# Menu a tendina per la selezione del prodotto\n",
    "product_dropdown = widgets.Dropdown(\n",
    "    options=[('Seleziona un prodotto', None)] + [(name, name) for name in manuals.keys()],\n",
    "    value=None,\n",
    "    description='Prodotto:',\n",
    ")\n",
    "\n",
    "# Campo di inserimento per la domanda\n",
    "query_input = widgets.Text(\n",
    "    value='',\n",
    "    placeholder='Inserisci la tua domanda',\n",
    "    description='Domanda:',\n",
    ")\n",
    "\n",
    "# Pulsante di invio\n",
    "submit_button = widgets.Button(\n",
    "    description='Invia',\n",
    "    button_style='primary',\n",
    ")\n",
    "submit_button.on_click(on_submit)\n",
    "\n",
    "# Finestra di conversazione (modificata per visualizzare tutto il testo)\n",
    "conversation_output = widgets.Textarea(\n",
    "    value='',\n",
    "    placeholder='Le risposte verranno visualizzate qui...',\n",
    "    description='Conversazione:',\n",
    "    layout={'width': '100%', 'height': '400px'},\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "# Visualizza tutti i widget\n",
    "display(product_dropdown, query_input, submit_button, conversation_output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
