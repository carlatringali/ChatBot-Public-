{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#non riconosce la punteggiatura nella domanda, quindi da errore se lo scrivo nella risposta\n",
    "import re\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "class ManualLoader:\n",
    "    def __init__(self, manual_paths):\n",
    "        self.manuals = {}\n",
    "        self.load_manuals(manual_paths)\n",
    "\n",
    "    def load_manuals(self, paths):\n",
    "        for name, path in paths.items():\n",
    "            with open(path, 'r', encoding='utf-8') as file:\n",
    "                content = file.read()\n",
    "                # Dividi il contenuto in chunk usando '---' come delimitatore\n",
    "                self.manuals[name] = self._split_into_chunks(content)\n",
    "\n",
    "    def _split_into_chunks(self, text):\n",
    "        # Splitting the text based on '---' delimiter\n",
    "        return [chunk.strip() for chunk in text.split('---') if chunk.strip()]\n",
    "\n",
    "class AssemblyAssistantBot:\n",
    "    def __init__(self, manuals):\n",
    "        self.manual_loader = ManualLoader(manuals)\n",
    "        self.vectorizer = TfidfVectorizer()\n",
    "        self._fit_vectorizer()\n",
    "\n",
    "    def _fit_vectorizer(self):\n",
    "        all_chunks = []\n",
    "        for chunks in self.manual_loader.manuals.values():\n",
    "            all_chunks.extend(chunks)\n",
    "        self.vectorizer.fit(all_chunks)\n",
    "\n",
    "    def handle_query(self, product, query):\n",
    "        if product == \"Giraffa\":\n",
    "            return self._handle_giraffa_query(query)\n",
    "        else:\n",
    "            return self._handle_other_products_query(product, query)\n",
    "\n",
    "    def _handle_giraffa_query(self, query):\n",
    "        chunks = self.manual_loader.manuals.get(\"Giraffa\", [])\n",
    "        if not chunks:\n",
    "            return [\"Manuale Giraffa non trovato.\"]\n",
    "        \n",
    "        query_vec = self.vectorizer.transform([query])\n",
    "        results = []\n",
    "        \n",
    "        # Calcola la similarità e seleziona i chunk migliori\n",
    "        chunk_vecs = self.vectorizer.transform(chunks)\n",
    "        similarities = cosine_similarity(query_vec, chunk_vecs).flatten()\n",
    "        \n",
    "        for index, similarity in enumerate(similarities):\n",
    "            if similarity > 0.25:  # Threshold per la similarità\n",
    "                results.append(chunks[index])\n",
    "        \n",
    "        # Riduci la lunghezza delle risposte\n",
    "        results = self._truncate_responses(results)\n",
    "        \n",
    "        return results if results else [\"Nessuna informazione trovata per Giraffa.\"]\n",
    "\n",
    "    def _handle_other_products_query(self, product, query):\n",
    "        chunks = self.manual_loader.manuals.get(product, [])\n",
    "        if not chunks:\n",
    "            return [\"Manuale non trovato.\"]\n",
    "        \n",
    "        query_vec = self.vectorizer.transform([query])\n",
    "        results = []\n",
    "        \n",
    "        # Calcola la similarità e seleziona i chunk migliori\n",
    "        chunk_vecs = self.vectorizer.transform(chunks)\n",
    "        similarities = cosine_similarity(query_vec, chunk_vecs).flatten()\n",
    "        \n",
    "        for index, similarity in enumerate(similarities):\n",
    "            if similarity > 0.25:  # Threshold per la similarità\n",
    "                results.append(chunks[index])\n",
    "        \n",
    "        # Riduci la lunghezza delle risposte\n",
    "        results = self._truncate_responses(results)\n",
    "        \n",
    "        return results if results else [\"Nessuna informazione trovata.\"]\n",
    "\n",
    "    def _truncate_responses(self, responses, max_length=500):\n",
    "        # Truncare ogni risposta a una lunghezza massima\n",
    "        truncated_responses = []\n",
    "        for response in responses:\n",
    "            if len(response) > max_length:\n",
    "                truncated_responses.append(response[:max_length] + '...')\n",
    "            else:\n",
    "                truncated_responses.append(response)\n",
    "        return truncated_responses\n",
    "\n",
    "def on_submit(_):\n",
    "    product = product_dropdown.value\n",
    "    query = query_input.value\n",
    "    if product and query:\n",
    "        response = bot.handle_query(product, query)\n",
    "        conversation_output.clear_output()\n",
    "        with conversation_output:\n",
    "            print(f\"Tu: {query}\")\n",
    "            for info in response:\n",
    "                print(f\"Bot: {info}\")\n",
    "        query_input.value = \"\"\n",
    "    else:\n",
    "        with conversation_output:\n",
    "            print(\"Bot: Seleziona un prodotto e inserisci una domanda.\")\n",
    "\n",
    "# Percorsi ai manuali\n",
    "manuals = {\n",
    "    \"Treno Arancio\": \"C:\\\\Users\\\\marid\\\\OneDrive\\\\Desktop\\\\Progetto SF\\\\TrenoArancio.txt\",\n",
    "    \"Treno Viola\": \"C:\\\\Users\\\\marid\\\\OneDrive\\\\Desktop\\\\Progetto SF\\\\TrenoViola.txt\",\n",
    "    \"Giraffa\": \"C:\\\\Users\\\\marid\\\\OneDrive\\\\Desktop\\\\Progetto SF\\\\Giraffa.txt\"\n",
    "}\n",
    "\n",
    "# Creazione del bot\n",
    "bot = AssemblyAssistantBot(manuals)\n",
    "\n",
    "# Menu a tendina per la selezione del prodotto (inizialmente popolato)\n",
    "product_dropdown = widgets.Dropdown(\n",
    "    options=[('Seleziona un prodotto', None)] + [(name, name) for name in manuals.keys()],\n",
    "    value=None,\n",
    "    description='Prodotto:',\n",
    ")\n",
    "\n",
    "# Campo di inserimento per la domanda\n",
    "query_input = widgets.Text(\n",
    "    value='',\n",
    "    placeholder='Inserisci la tua domanda',\n",
    "    description='Domanda:',\n",
    ")\n",
    "\n",
    "# Pulsante di invio\n",
    "submit_button = widgets.Button(\n",
    "    description='Invia',\n",
    "    button_style='primary',\n",
    ")\n",
    "submit_button.on_click(on_submit)\n",
    "\n",
    "# Finestra di conversazione\n",
    "conversation_output = widgets.Output()\n",
    "\n",
    "# Visualizza tutti i widget\n",
    "display(product_dropdown, query_input, submit_button, conversation_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc56dfbb138145c3bfb43eae079f1a01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Prodotto:', options=(('Seleziona un prodotto', None), ('Treno Arancio', 'Treno Arancio')…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25587096f0eb41919f9d9c0e293d30f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Domanda:', placeholder='Inserisci la tua domanda')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36dd6862a60d402d89c1097054bd256c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='primary', description='Invia', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "588f0ab026d24a2eb5d10458455f9429",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Riconosce la punteggiatura nella domanda e non da errore\n",
    "import re\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Converti il testo in minuscolo, ma non rimuovere la punteggiatura\n",
    "    return text.lower()\n",
    "\n",
    "class ManualLoader:\n",
    "    def __init__(self, manual_paths):\n",
    "        self.manuals = {}\n",
    "        self.load_manuals(manual_paths)\n",
    "\n",
    "    def load_manuals(self, paths):\n",
    "        for name, path in paths.items():\n",
    "            with open(path, 'r', encoding='utf-8') as file:\n",
    "                content = file.read()\n",
    "                # Dividi il contenuto in chunk usando '---' come delimitatore\n",
    "                self.manuals[name] = self._split_into_chunks(content)\n",
    "\n",
    "    def _split_into_chunks(self, text):\n",
    "        # Splitting the text based on '---' delimiter and preprocessing\n",
    "        chunks = [preprocess_text(chunk.strip()) for chunk in text.split('---') if chunk.strip()]\n",
    "        return chunks\n",
    "\n",
    "class AssemblyAssistantBot:\n",
    "    def __init__(self, manuals):\n",
    "        self.manual_loader = ManualLoader(manuals)\n",
    "        self.vectorizer = TfidfVectorizer()\n",
    "        self._fit_vectorizer()\n",
    "\n",
    "    def _fit_vectorizer(self):\n",
    "        all_chunks = []\n",
    "        for chunks in self.manual_loader.manuals.values():\n",
    "            all_chunks.extend(chunks)\n",
    "        self.vectorizer.fit(all_chunks)\n",
    "\n",
    "    def handle_query(self, product, query):\n",
    "        query = preprocess_text(query)\n",
    "        if product == \"Giraffa\":\n",
    "            return self._handle_giraffa_query(query)\n",
    "        else:\n",
    "            return self._handle_other_products_query(product, query)\n",
    "\n",
    "    def _handle_giraffa_query(self, query):\n",
    "        chunks = self.manual_loader.manuals.get(\"Giraffa\", [])\n",
    "        if not chunks:\n",
    "            return [\"Manuale Giraffa non trovato.\"]\n",
    "        \n",
    "        query_vec = self.vectorizer.transform([query])\n",
    "        results = []\n",
    "        \n",
    "        # Calcola la similarità e seleziona i chunk migliori\n",
    "        chunk_vecs = self.vectorizer.transform(chunks)\n",
    "        similarities = cosine_similarity(query_vec, chunk_vecs).flatten()\n",
    "        \n",
    "        for index, similarity in enumerate(similarities):\n",
    "            if similarity > 0.25:  # Threshold per la similarità\n",
    "                results.append(chunks[index])\n",
    "        \n",
    "        # Riduci la lunghezza delle risposte\n",
    "        results = self._truncate_responses(results)\n",
    "        \n",
    "        return results if results else [\"Nessuna informazione trovata per Giraffa.\"]\n",
    "\n",
    "    def _handle_other_products_query(self, product, query):\n",
    "        chunks = self.manual_loader.manuals.get(product, [])\n",
    "        if not chunks:\n",
    "            return [\"Manuale non trovato.\"]\n",
    "        \n",
    "        query_vec = self.vectorizer.transform([query])\n",
    "        results = []\n",
    "        \n",
    "        # Calcola la similarità e seleziona i chunk migliori\n",
    "        chunk_vecs = self.vectorizer.transform(chunks)\n",
    "        similarities = cosine_similarity(query_vec, chunk_vecs).flatten()\n",
    "        \n",
    "        for index, similarity in enumerate(similarities):\n",
    "            if similarity > 0.25:  # Threshold per la similarità\n",
    "                results.append(chunks[index])\n",
    "        \n",
    "        # Riduci la lunghezza delle risposte\n",
    "        results = self._truncate_responses(results)\n",
    "        \n",
    "        return results if results else [\"Nessuna informazione trovata.\"]\n",
    "\n",
    "    def _truncate_responses(self, responses, max_length=500):\n",
    "        # Truncare ogni risposta a una lunghezza massima\n",
    "        truncated_responses = []\n",
    "        for response in responses:\n",
    "            if len(response) > max_length:\n",
    "                truncated_responses.append(response[:max_length] + '...')\n",
    "            else:\n",
    "                truncated_responses.append(response)\n",
    "        return truncated_responses\n",
    "\n",
    "def on_submit(_):\n",
    "    product = product_dropdown.value\n",
    "    query = query_input.value\n",
    "    if product and query:\n",
    "        response = bot.handle_query(product, query)\n",
    "        conversation_output.clear_output()\n",
    "        with conversation_output:\n",
    "            print(f\"Tu: {query}\")\n",
    "            for info in response:\n",
    "                print(f\"Bot: {info}\")\n",
    "        query_input.value = \"\"\n",
    "    else:\n",
    "        with conversation_output:\n",
    "            print(\"Bot: Seleziona un prodotto e inserisci una domanda.\")\n",
    "\n",
    "# Percorsi ai manuali\n",
    "manuals = {\n",
    "    \"Treno Arancio\": \"C:\\\\Users\\\\marid\\\\OneDrive\\\\Desktop\\\\Progetto SF\\\\TrenoArancio.txt\",\n",
    "    \"Treno Viola\": \"C:\\\\Users\\\\marid\\\\OneDrive\\\\Desktop\\\\Progetto SF\\\\TrenoViola.txt\",\n",
    "    \"Giraffa\": \"C:\\\\Users\\\\marid\\\\OneDrive\\\\Desktop\\\\Progetto SF\\\\Giraffa.txt\"\n",
    "}\n",
    "\n",
    "# Creazione del bot\n",
    "bot = AssemblyAssistantBot(manuals)\n",
    "\n",
    "# Menu a tendina per la selezione del prodotto (inizialmente popolato)\n",
    "product_dropdown = widgets.Dropdown(\n",
    "    options=[('Seleziona un prodotto', None)] + [(name, name) for name in manuals.keys()],\n",
    "    value=None,\n",
    "    description='Prodotto:',\n",
    ")\n",
    "\n",
    "# Campo di inserimento per la domanda\n",
    "query_input = widgets.Text(\n",
    "    value='',\n",
    "    placeholder='Inserisci la tua domanda',\n",
    "    description='Domanda:',\n",
    ")\n",
    "\n",
    "# Pulsante di invio\n",
    "submit_button = widgets.Button(\n",
    "    description='Invia',\n",
    "    button_style='primary',\n",
    ")\n",
    "submit_button.on_click(on_submit)\n",
    "\n",
    "# Finestra di conversazione\n",
    "conversation_output = widgets.Output()\n",
    "\n",
    "# Visualizza tutti i widget\n",
    "display(product_dropdown, query_input, submit_button, conversation_output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
